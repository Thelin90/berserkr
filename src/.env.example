# .env

#pyspark packages
DELTA_LOGSTORE = spark.delta.logStore.class=org.apache.spark.sql.delta.storage.S3SingleDriverLogStore
DELTA = io.delta:delta-core_x.xx:x.x.x
HADOOP_COMMON = org.apache.hadoop:hadoop-common:x.x.x
HADOOP_AWS = org.apache.hadoop:hadoop-aws:x.x.x
PYSPARK_SUBMIT_ARGS = ${HADOOP_AWS},${HADOOP_COMMON},${DELTA}
PYSPARK_CONF_ARGS = ${DELTA_LOGSTORE}

# Online Retailer R2P
RAW_TO_PARQUET_WAREHOUSE_LOCATION=
RAW_TO_PARQUET_APP_NAME=
RAW_DATA_ONLINE_RETAIL_S3_BUCKET=
PARQUET_DATA_ONLINE_RETAIL_S3_BUCKET=

# AWS
AWS_ENDPOINT_URL=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
SIGNATURE_VERSION=